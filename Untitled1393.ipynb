{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48530d26-8aab-4035-b7cd-d16cd16f87d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_model.pkl\n",
      "[INFO] Loading data: C:\\Users\\sagni\\Downloads\\Cardio Track\\archive\\heart.csv\n",
      "[INFO] Data shape: 1025 x 14\n",
      "[INFO] Inferred target column: target\n",
      "[INFO] Running predictions...\n",
      "[OK] Saved predictions CSV: C:\\Users\\sagni\\Downloads\\Cardio Track\\predictions.csv\n",
      "[OK] Saved summary JSON: C:\\Users\\sagni\\Downloads\\Cardio Track\\prediction_summary.json\n",
      "[OK] Saved metrics JSON (since target present): C:\\Users\\sagni\\Downloads\\Cardio Track\\prediction_metrics.json\n",
      "\n",
      "=== Preview (first 5 rows) ===\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  predicted  proba_1  proba_0  \n",
      "0   2     3       0          0   0.0250   0.9750  \n",
      "1   0     3       0          0   0.0150   0.9850  \n",
      "2   0     3       0          0   0.0050   0.9950  \n",
      "3   1     3       0          0   0.0050   0.9950  \n",
      "4   3     2       0          0   0.0325   0.9675  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "DEFAULT_MODEL  = r\"C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_model.pkl\"\n",
    "DEFAULT_INPUT  = r\"C:\\Users\\sagni\\Downloads\\Cardio Track\\archive\\heart.csv\"\n",
    "DEFAULT_OUTDIR = r\"C:\\Users\\sagni\\Downloads\\Cardio Track\"\n",
    "\n",
    "POSSIBLE_TARGETS = [\n",
    "    \"target\", \"Target\", \"TARGET\",\n",
    "    \"output\", \"Output\",\n",
    "    \"diagnosis\", \"Diagnosis\",\n",
    "    \"label\", \"Label\",\n",
    "    \"HeartDisease\", \"heart_disease\"\n",
    "]\n",
    "\n",
    "def guess_target_column(df: pd.DataFrame) -> str | None:\n",
    "    for col in POSSIBLE_TARGETS:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    # Heuristic: low-cardinality last column\n",
    "    last = df.columns[-1]\n",
    "    try:\n",
    "        if df[last].dropna().nunique() <= 10:\n",
    "            return last\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"CardioTrack batch prediction\")\n",
    "    parser.add_argument(\"--model\",  default=DEFAULT_MODEL,  help=\"Path to joblib .pkl model pipeline\")\n",
    "    parser.add_argument(\"--input\",  default=DEFAULT_INPUT,  help=\"Path to input CSV\")\n",
    "    parser.add_argument(\"--outdir\", default=DEFAULT_OUTDIR, help=\"Output directory\")\n",
    "\n",
    "    parser.add_argument(\"--target\", default=None, help=\"Name of target column (optional)\")\n",
    "    parser.add_argument(\"--id_col\", default=None, help=\"Optional ID column to carry into outputs\")\n",
    "\n",
    "    parser.add_argument(\"--pred_name\", default=\"predicted\", help=\"Name of the prediction column in output CSV\")\n",
    "    parser.add_argument(\"--proba1_name\", default=\"proba_1\", help=\"Column name for positive-class probability\")\n",
    "    parser.add_argument(\"--proba0_name\", default=\"proba_0\", help=\"Column name for negative-class probability\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    model_path = args.model\n",
    "    input_path = args.input\n",
    "    outdir     = args.outdir\n",
    "    target_col = args.target\n",
    "    id_col     = args.id_col\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # ---------- Load model ----------\n",
    "    print(\"[INFO] Loading model:\", model_path)\n",
    "    pipe = joblib.load(model_path)\n",
    "\n",
    "    # ---------- Load data ----------\n",
    "    print(\"[INFO] Loading data:\", input_path)\n",
    "    df = pd.read_csv(input_path).dropna(how=\"all\").reset_index(drop=True)\n",
    "    n_rows, n_cols = df.shape\n",
    "    print(f\"[INFO] Data shape: {n_rows} x {n_cols}\")\n",
    "\n",
    "    # Detect target if not explicitly provided\n",
    "    inferred_target = guess_target_column(df)\n",
    "    if target_col is None and inferred_target is not None:\n",
    "        target_col = inferred_target\n",
    "        print(f\"[INFO] Inferred target column: {target_col}\")\n",
    "\n",
    "    # Separate features and (optional) ground truth\n",
    "    if target_col and target_col in df.columns:\n",
    "        y_true = df[target_col].copy()\n",
    "        X = df.drop(columns=[target_col])\n",
    "    else:\n",
    "        y_true = None\n",
    "        X = df\n",
    "\n",
    "    # Keep ID column (if any) aside to re-attach later\n",
    "    id_series = None\n",
    "    if id_col and id_col in X.columns:\n",
    "        id_series = X[id_col].copy()\n",
    "        X = X.drop(columns=[id_col])\n",
    "\n",
    "    # ---------- Predict ----------\n",
    "    print(\"[INFO] Running predictions...\")\n",
    "    y_pred = pipe.predict(X)\n",
    "\n",
    "    proba_1 = None\n",
    "    proba_0 = None\n",
    "    if hasattr(pipe, \"predict_proba\"):\n",
    "        try:\n",
    "            probs = pipe.predict_proba(X)\n",
    "            # Determine which column is the \"positive class\" for binary case\n",
    "            # scikit-learn: classes_ attribute holds class order\n",
    "            classes = getattr(pipe, \"classes_\", None)\n",
    "            # If pipeline, access final estimator's classes_\n",
    "            if classes is None and hasattr(pipe, \"named_steps\") and \"model\" in pipe.named_steps:\n",
    "                classes = getattr(pipe.named_steps[\"model\"], \"classes_\", None)\n",
    "\n",
    "            if classes is not None and len(classes) == 2:\n",
    "                # Proba for positive class = class with max label, or assume class 1 if present\n",
    "                # Prefer class \"1\" if available\n",
    "                pos_index = 1 if 1 in classes else np.argmax(classes)\n",
    "                proba_1 = probs[:, list(classes).index(pos_index)] if pos_index in classes else probs[:, 1]\n",
    "                proba_0 = 1.0 - proba_1\n",
    "            else:\n",
    "                # Multiclass or unknown schema: store only max probability\n",
    "                proba_1 = probs.max(axis=1)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] predict_proba not available or failed:\", str(e))\n",
    "\n",
    "    # ---------- Build output ----------\n",
    "    out_df = df.copy()\n",
    "    out_df[args.pred_name] = y_pred\n",
    "\n",
    "    if proba_1 is not None:\n",
    "        out_df[args.proba1_name] = proba_1\n",
    "    if proba_0 is not None:\n",
    "        out_df[args.proba0_name] = proba_0\n",
    "\n",
    "    # Re-attach ID if we pulled it out earlier (ensure same order)\n",
    "    if id_series is not None and id_col not in out_df.columns:\n",
    "        out_df.insert(0, id_col, id_series.values)\n",
    "\n",
    "    # ---------- Save predictions ----------\n",
    "    pred_csv = os.path.join(outdir, \"predictions.csv\")\n",
    "    out_df.to_csv(pred_csv, index=False)\n",
    "    print(\"[OK] Saved predictions CSV:\", pred_csv)\n",
    "\n",
    "    # ---------- Summary JSON ----------\n",
    "    summary = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_path\": model_path,\n",
    "        \"input_path\": input_path,\n",
    "        \"n_rows\": int(n_rows),\n",
    "        \"n_cols\": int(n_cols),\n",
    "        \"target_in_input\": bool(target_col and target_col in df.columns),\n",
    "        \"pred_column\": args.pred_name,\n",
    "        \"proba_1_column\": (args.proba1_name if proba_1 is not None else None),\n",
    "        \"proba_0_column\": (args.proba0_name if proba_0 is not None else None)\n",
    "    }\n",
    "    summary_json = os.path.join(outdir, \"prediction_summary.json\")\n",
    "    with open(summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(\"[OK] Saved summary JSON:\", summary_json)\n",
    "\n",
    "    # ---------- Optional: Metrics if ground truth present ----------\n",
    "    if target_col and target_col in df.columns:\n",
    "        y_true_proc = y_true.copy()\n",
    "\n",
    "        # Normalize common binary label quirks for fair metrics\n",
    "        uniq = sorted(pd.unique(y_true_proc.dropna()))\n",
    "        if set(uniq) == {1, 2}:\n",
    "            y_true_proc = y_true_proc.replace({2: 1})\n",
    "        elif set(uniq) == {0, 2}:\n",
    "            y_true_proc = y_true_proc.replace({2: 1})\n",
    "\n",
    "        metrics = {}\n",
    "        try:\n",
    "            acc = accuracy_score(y_true_proc, y_pred)\n",
    "            metrics[\"accuracy\"] = float(acc)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # AUROC for binary only and if probabilities available\n",
    "        try:\n",
    "            if proba_1 is not None and len(np.unique(y_true_proc.dropna())) == 2:\n",
    "                # ensure probs not constant\n",
    "                if not np.allclose(np.min(proba_1), np.max(proba_1)):\n",
    "                    auc = roc_auc_score(y_true_proc, proba_1)\n",
    "                    metrics[\"roc_auc\"] = float(auc)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Confusion matrix (safe)\n",
    "        try:\n",
    "            labels_sorted = np.unique(np.concatenate([y_true_proc.values, y_pred]))\n",
    "            cm = confusion_matrix(y_true_proc, y_pred, labels=labels_sorted).tolist()\n",
    "            metrics[\"labels\"] = [int(x) if isinstance(x, (np.integer,)) else (x.item() if isinstance(x, np.generic) else x)\n",
    "                                 for x in labels_sorted]\n",
    "            metrics[\"confusion_matrix\"] = cm\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        metrics_path = os.path.join(outdir, \"prediction_metrics.json\")\n",
    "        with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        print(\"[OK] Saved metrics JSON (since target present):\", metrics_path)\n",
    "\n",
    "    # ---------- Preview ----------\n",
    "    print(\"\\n=== Preview (first 5 rows) ===\")\n",
    "    with pd.option_context(\"display.max_columns\", None):\n",
    "        print(out_df.head(5))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a69af2-a62a-4489-83af-98bc0ecae854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
