{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d634a908-2333-4e41-bd78-bfd61cea9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading: C:\\Users\\sagni\\Downloads\\Cardio Track\\archive\\heart.csv\n",
      "[INFO] Training LogisticRegression ...\n",
      "[INFO] Training RandomForest ...\n",
      "[OK] Saved accuracy chart: C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_accuracy.png\n",
      "[OK] Saved confusion heatmap: C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_confusion_heatmap.png\n",
      "[OK] Saved metrics JSON: C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_metrics.json\n",
      "\n",
      "=== Done ===\n",
      "Accuracy chart -> C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_accuracy.png\n",
      "Heatmap        -> C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_confusion_heatmap.png\n",
      "Metrics JSON   -> C:\\Users\\sagni\\Downloads\\Cardio Track\\cardiotrack_metrics.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # for headless environments\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "POSSIBLE_TARGETS = [\n",
    "    \"target\", \"Target\", \"TARGET\",\n",
    "    \"output\", \"Output\",\n",
    "    \"diagnosis\", \"Diagnosis\",\n",
    "    \"label\", \"Label\",\n",
    "    \"HeartDisease\", \"heart_disease\"\n",
    "]\n",
    "\n",
    "def guess_target_column(df: pd.DataFrame) -> str:\n",
    "    for col in POSSIBLE_TARGETS:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    last = df.columns[-1]\n",
    "    if df[last].dropna().nunique() <= 10:\n",
    "        return last\n",
    "    for col in df.columns[::-1]:\n",
    "        if df[col].dropna().nunique() <= 10:\n",
    "            return col\n",
    "    return df.columns[-1]\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"CardioTrack accuracy chart + confusion heatmap\")\n",
    "    parser.add_argument(\n",
    "        \"--csv\",\n",
    "        default=r\"C:\\Users\\sagni\\Downloads\\Cardio Track\\archive\\heart.csv\",\n",
    "        help=\"Path to heart.csv\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out\",\n",
    "        default=r\"C:\\Users\\sagni\\Downloads\\Cardio Track\",\n",
    "        help=\"Output directory for plots/metrics\"\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    csv_path = args.csv\n",
    "    out_dir  = args.out\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    print(\"[INFO] Loading:\", csv_path)\n",
    "    df = pd.read_csv(csv_path).dropna(how=\"all\").reset_index(drop=True)\n",
    "\n",
    "    target_col = guess_target_column(df)\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Target column not found. Guessed: {target_col}\")\n",
    "\n",
    "    y = df[target_col].copy()\n",
    "\n",
    "    # Normalize common label oddities to 0/1 where possible\n",
    "    uniq = sorted(pd.unique(y.dropna()))\n",
    "    if set(uniq) == {1, 2}:\n",
    "        y = y.replace({2: 1})\n",
    "    elif set(uniq) == {0, 2}:\n",
    "        y = y.replace({2: 1})\n",
    "    elif y.dtype == object:\n",
    "        # map strings to integers deterministically\n",
    "        mapping = {v: i for i, v in enumerate(sorted(y.dropna().unique()))}\n",
    "        y = y.map(mapping)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "\n",
    "    num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    numeric_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_tf, num_cols),\n",
    "            (\"cat\", categorical_tf, cat_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=400, random_state=42, n_jobs=-1\n",
    "        )\n",
    "    }\n",
    "\n",
    "    stratify = y if y.nunique() > 1 else None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=stratify\n",
    "    )\n",
    "\n",
    "    metrics = {}\n",
    "    best_name, best_score, best_pipe = None, -np.inf, None\n",
    "\n",
    "    for name, est in models.items():\n",
    "        pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", est)])\n",
    "        print(f\"[INFO] Training {name} ...\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        auc = None\n",
    "        try:\n",
    "            if len(np.unique(y_test)) == 2:\n",
    "                if hasattr(pipe, \"predict_proba\"):\n",
    "                    y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "                elif hasattr(pipe, \"decision_function\"):\n",
    "                    scores = pipe.decision_function(X_test)\n",
    "                    y_prob = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
    "                else:\n",
    "                    y_prob = None\n",
    "                if y_prob is not None and not np.allclose(y_prob.min(), y_prob.max()):\n",
    "                    auc = roc_auc_score(y_test, y_prob)\n",
    "        except Exception:\n",
    "            auc = None\n",
    "\n",
    "        # choose by AUROC if available else accuracy\n",
    "        chosen = auc if auc is not None else acc\n",
    "        metrics[name] = {\"accuracy\": float(acc), \"roc_auc\": (None if auc is None else float(auc)),\n",
    "                         \"chosen_score\": float(chosen)}\n",
    "        if chosen > best_score:\n",
    "            best_score = chosen\n",
    "            best_name = name\n",
    "            best_pipe = pipe\n",
    "\n",
    "    # -------- Accuracy bar chart --------\n",
    "    acc_fig_path = os.path.join(out_dir, \"cardiotrack_accuracy.png\")\n",
    "    names = list(metrics.keys())\n",
    "    accuracies = [metrics[n][\"accuracy\"] for n in names]\n",
    "\n",
    "    plt.figure(figsize=(7, 5), dpi=140)\n",
    "    bars = plt.bar(names, accuracies)\n",
    "    plt.title(\"Model Accuracy (Test Set)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    for bar, val in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, val + 0.01, f\"{val:.3f}\",\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "    print(\"[OK] Saved accuracy chart:\", acc_fig_path)\n",
    "\n",
    "    # -------- Confusion matrix heatmap (best model) --------\n",
    "    y_pred_best = best_pipe.predict(X_test)\n",
    "    labels_sorted = np.unique(np.concatenate([y_test, y_pred_best]))\n",
    "    cm = confusion_matrix(y_test, y_pred_best, labels=labels_sorted)\n",
    "\n",
    "    heatmap_path = os.path.join(out_dir, \"cardiotrack_confusion_heatmap.png\")\n",
    "    plt.figure(figsize=(6, 5), dpi=140)\n",
    "    im = plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(f\"Confusion Matrix (Best: {best_name})\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(labels_sorted))\n",
    "    plt.xticks(tick_marks, labels_sorted)\n",
    "    plt.yticks(tick_marks, labels_sorted)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    # annotate cells\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "    print(\"[OK] Saved confusion heatmap:\", heatmap_path)\n",
    "\n",
    "    # -------- Save metrics JSON --------\n",
    "    out_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"csv_path\": csv_path,\n",
    "        \"target\": target_col,\n",
    "        \"metrics\": metrics,\n",
    "        \"best_model\": best_name,\n",
    "        \"labels\": [int(x) if isinstance(x, (np.integer,)) else (x.item() if isinstance(x, np.generic) else x)\n",
    "                   for x in labels_sorted]\n",
    "    }\n",
    "    metrics_path = os.path.join(out_dir, \"cardiotrack_metrics.json\")\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out_metrics, f, indent=2)\n",
    "    print(\"[OK] Saved metrics JSON:\", metrics_path)\n",
    "\n",
    "    print(\"\\n=== Done ===\")\n",
    "    print(\"Accuracy chart ->\", acc_fig_path)\n",
    "    print(\"Heatmap        ->\", heatmap_path)\n",
    "    print(\"Metrics JSON   ->\", metrics_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851fd83-8741-4f17-bce6-9e6b9bb6260e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
